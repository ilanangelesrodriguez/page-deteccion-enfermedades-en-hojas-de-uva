# -*- coding: utf-8 -*-
"""CNN_clasificación_de_enfermedades_de_la_hoja_de_la_uva.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i7DB_9U-oxj5SVSy8ywcOs4NDVwvKiMR

# Curso de Inteligencia de Negocios

## Proyecto: Detección de Enfermedades en las Hojas de la Uva

---

### Integrantes:
- **Angeles Rodriguez, Ilan**
- **Loma Aguirre, Mariesther**

---

### Docente:
- **Dr. Alfredo Daza Vergaray**

---

### Descripción del Proyecto:
En este proyecto, desarrollaremos un modelo de aprendizaje automático para la detección de enfermedades en las hojas de la vid. Utilizaremos técnicas avanzadas de procesamiento de imágenes y redes neuronales convolucionales (CNN) para clasificar las hojas de la vid en diferentes categorías de enfermedades. Este enfoque ayudará a mejorar la gestión y el tratamiento de los viñedos, contribuyendo a la producción sostenible de uvas.

---

### Universidad Nacional del Santa
#### Facultad de Ingeniería
#### Escuela Profesional de Ingeniería de Sistemas
#### 2024

# Importar Librerias
"""

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'augmented-grape-disease-detection-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2869270%2F4948090%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240711%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240711T173105Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D61ed80e1e4cf5a20fab5f8aa9446649190b8efa9635cbc0276e0a7683f00a274410f3b7a52489d4ff9c794b2f2d471550d17cc8edd627f7508ea5311c1353da7e31b268a79b61f93a12b6d9c4f8490d8ddb537b42e770a899e5c28ac8b431b5141ffbb5e04ccc511061ef5f2ce701c6c871fa06c8967d9b5e5edf2eecaa9d83a150b8d14fd33bcb30848d9c5a563dc1ba2ae7662f41de3d5abdd06563d4c6bb47193fba90502f8623c675cd1029b4178d01bf6542f1eb55ec0a95a20a2ac2fc410b455a3fe168db59ccdc90ce664c59f1cddb147cce052f8bbaf993c11098aaf065bb73be7f523e620516a6d49737c0c2002a955605b29f81872692619f7fea3'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import numpy as np
import pandas as pd

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""# Introducción

## Tiene clases con 1344 imágenes aumentadas y 1656 imágenes del conjunto de datos original, para un total de 3000 imágenes por clase. Las cuatro clases son Black Rot, ESCA, Leaf Blight y Healthy.

# Objetivo

## Clasificar las imágenes con las siguientes etiquetas: Black Rot, Healthy, Leaf Blight y Healthy.

## Importar librerias
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from PIL import Image
import cv2
plt.style.use('ggplot')


import os

import warnings
warnings.filterwarnings('ignore')

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

from tensorflow.keras.models import Sequential
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Dense, Flatten, InputLayer, Reshape, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization

"""## Análisis Exploratorio de Datos (EDA)"""

labels = ["Black Rot", "ESCA", "Healthy", "Leaf Blight"]
img_path = "/kaggle/input/augmented-grape-disease-detection-dataset/Final Training Data/"

img_list = []
label_list = []

for label in labels:
    for img in os.listdir(img_path+label):
        img_list.append(img_path+label+"/"+img)
        label_list.append(label)

img_list[:5]

sns.countplot(x=label_list);

df = pd.DataFrame({"image":img_list, "label":label_list})
df.sample(9)

img = cv2.imread(df.image[5445])
plt.imshow(img);

img.shape

d = {"Black Rot":0, "ESCA":1, "Healthy":2, "Leaf Blight":3}
df["encoded_label"] = df.label.map(d)
df.sample(5)

sns.countplot(x="encoded_label", data=df);

"""## Preprocesamiento de datos"""

X = []

for img in df["image"]:
    img = cv2.imread(img)
    img = cv2.resize(img, (50, 50))
    img = img/255.0
    X.append(img)

X = np.array(X)

y = df["encoded_label"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

"""## Modelado"""

model = Sequential()

model.add(InputLayer(input_shape=(50,50,3)))

model.add(Conv2D(16, (3,3), activation="relu"))
model.add(Conv2D(32, (3,3), activation="relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(64, (3,3), activation="relu"))
model.add(Conv2D(128, (3,3), activation="relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Flatten())

model.add(Dense(512, activation="relu"))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(4, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

history = model.fit(X_train, y_train, epochs=7, batch_size=32, validation_data=(X_test, y_test))

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Loss: {loss:.3f},\nAccuracy: {accuracy*100:.2f}%")

model.save("model_grapevine_disease_detection.h5")

model = load_model("model_grapevine_disease_detection.h5")



import matplotlib.pyplot as plt

def plot_training_history(model_name, model_history):
    ### Exactitud del entrenamiento:
    # Configurando figsize y dpi para el gráfico
    plt.figure(figsize=(6, 4), dpi=96)
    # Trazando la exactitud
    plt.plot(model_history.history['accuracy'])
    # Trazando la exactitud de validación
    plt.plot(model_history.history['val_accuracy'])
    # Añadiendo el título
    plt.title(f'Exactitud de {model_name}')
    # Añadiendo las etiquetas de los ejes x e y
    plt.xlabel('Épocas')
    plt.ylabel('Exactitud')
    # Añadiendo la leyenda
    plt.legend(['Entrenamiento', 'Validación'], loc='lower right')
    # Mostrando el gráfico
    plt.show()

    ### Pérdida del entrenamiento:
    # Configurando figsize y dpi para el gráfico
    plt.figure(figsize=(6, 4), dpi=96)
    # Trazando la pérdida
    plt.plot(model_history.history['loss'])
    # Trazando la pérdida de validación
    plt.plot(model_history.history['val_loss'])
    # Añadiendo el título
    plt.title(f'Pérdida de {model_name}')
    # Añadiendo las etiquetas de los ejes x e y
    plt.xlabel('Épocas')
    plt.ylabel('Pérdida')
    # Añadiendo la leyenda
    plt.legend(['Entrenamiento', 'Validación'], loc='upper right')
    # Mostrando el gráfico
    plt.show()

# Llamada a la función con el nombre del modelo y el historial de entrenamiento
plot_training_history('Detección de Enfermedades de la Vid', history)

"""## Predicción"""

pred = model.predict(X_test)
pred

pred_probabilities = model.predict(X_test)
pred_classes = np.argmax(pred_probabilities, axis=-1)

pred_classes

df_pred = pd.DataFrame({"Actual":y_test, "Predicted":pred_classes}, )
df_pred["Result"] = df_pred["Predicted"].replace({0:"Black Rot", 1:"ESCA", 2:"Healthy", 3:"Leaf Blight"})
df_pred

sns.countplot(x="Result", data=df_pred);

"""### Matriz de confusión"""

sns.heatmap(confusion_matrix(y_test, pred_classes),annot=True, fmt="d", cmap="Reds");

"""### Métricas de Evaluación"""

from sklearn.metrics import classification_report, precision_score, recall_score, f1_score

# Calculando precisión, recall y F1-score
precision = precision_score(y_test, pred_classes, average='weighted')
recall = recall_score(y_test, pred_classes, average='weighted')
f1 = f1_score(y_test, pred_classes, average='weighted')

print(f"Precisión: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-score: {f1:.2f}")

# Generando el reporte de clasificación
class_report = classification_report(y_test, pred_classes, target_names=labels)
print("Reporte de Clasificación:\n", class_report)





"""### Visualización de errores"""

"""### Visualización de errores"""

import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

def plot_model_errors(final_model_predictions, test_images, test_labels, error_rows=4, error_cols=4):
    ### Visualización de errores
    # Obteniendo índices de errores del modelo
    model_errors = (final_model_predictions != test_labels)
    # Obteniendo las imágenes correspondientes
    model_image_errors = test_images[model_errors]
    # Obteniendo las etiquetas predichas
    model_pred_errors = np.array(final_model_predictions)[model_errors]
    # Obteniendo las etiquetas reales
    model_actual_errors = np.array(test_labels)[model_errors]

    # Función que añade un marco alrededor de la imagen
    def frame_image(image, frame_width):
        # Obteniendo dimensiones de la imagen en píxeles
        y_pixels, x_pixels = image.shape[0], image.shape[1]
        # Creando una imagen RGB negra con dimensiones frame_width*2 + y_pixels y frame_width*2 + x_pixels
        empty_image = Image.new('RGB', (frame_width*2 + x_pixels, frame_width*2 + y_pixels), (0, 0, 0))
        # Convirtiendo la imagen vacía a un array numpy
        framed_image = np.array(empty_image)
        # Añadiendo la imagen original dentro del marco
        framed_image[frame_width:frame_width+y_pixels, frame_width:frame_width+x_pixels] = image
        # Devolviendo la imagen enmarcada
        return framed_image

    # Índice de error
    n = 0
    # Subgráficos
    fig, ax = plt.subplots(error_rows, error_cols, figsize=(9.5, 10))
    fig.suptitle('Visualización de errores', fontsize=20)
    # Iterando sobre las filas
    for row in range(error_rows):
        # Iterando sobre las columnas
        for col in range(error_cols):
            try:
                # Añadir el título
                ax[row, col].set_title(f'E. Predicha: {model_pred_errors[n]}\nE. Real: {model_actual_errors[n]}')
                # Graficar la imagen
                ax[row, col].imshow(frame_image((model_image_errors[n]*255).astype(np.uint8), 5))
                # Configurar la relación de aspecto
                ax[row, col].set_aspect(aspect=1)
                # Incrementar el índice de error
                n += 1
            except IndexError:
                # No hacer nada si no hay más imágenes de error
                pass
            # Eliminar el eje
            ax[row, col].axis('off')
    # Mostrar los subgráficos
    plt.show()

# Llamada a la función con las predicciones finales, imágenes de prueba y etiquetas de prueba
plot_model_errors(pred_classes, X_test, y_test)